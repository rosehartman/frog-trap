<!DOCTYPE html>
<!-- saved from url=(0014)about:internet -->
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
<meta http-equiv="x-ua-compatible" content="IE=9" >

<title>Trap model analytics</title>

<style type="text/css">
body, td {
   font-family: sans-serif;
   background-color: white;
   font-size: 12px;
   margin: 8px;
}

tt, code, pre {
   font-family: 'DejaVu Sans Mono', 'Droid Sans Mono', 'Lucida Console', Consolas, Monaco, monospace;
}

h1 { 
   font-size:2.2em; 
}

h2 { 
   font-size:1.8em; 
}

h3 { 
   font-size:1.4em; 
}

h4 { 
   font-size:1.0em; 
}

h5 { 
   font-size:0.9em; 
}

h6 { 
   font-size:0.8em; 
}

a:visited {
   color: rgb(50%, 0%, 50%);
}

pre {	
   margin-top: 0;
   max-width: 95%;
   border: 1px solid #ccc;
   white-space: pre-wrap;
}

pre code {
   display: block; padding: 0.5em;
}

code.r, code.cpp {
   background-color: #F8F8F8;
}

table, td, th {
  border: none;
}

blockquote {
   color:#666666;
   margin:0;
   padding-left: 1em;
   border-left: 0.5em #EEE solid;
}

hr {
   height: 0px;
   border-bottom: none;
   border-top-width: thin;
   border-top-style: dotted;
   border-top-color: #999999;
}

@media print {
   * { 
      background: transparent !important; 
      color: black !important; 
      filter:none !important; 
      -ms-filter: none !important; 
   }

   body { 
      font-size:12pt; 
      max-width:100%; 
   }
       
   a, a:visited { 
      text-decoration: underline; 
   }

   hr { 
      visibility: hidden;
      page-break-before: always;
   }

   pre, blockquote { 
      padding-right: 1em; 
      page-break-inside: avoid; 
   }

   tr, img { 
      page-break-inside: avoid; 
   }

   img { 
      max-width: 100% !important; 
   }

   @page :left { 
      margin: 15mm 20mm 15mm 10mm; 
   }
     
   @page :right { 
      margin: 15mm 10mm 15mm 20mm; 
   }

   p, h2, h3 { 
      orphans: 3; widows: 3; 
   }

   h2, h3 { 
      page-break-after: avoid; 
   }
}

</style>



<!-- MathJax scripts -->
<script type="text/javascript" src="https://c328740.ssl.cf1.rackcdn.com/mathjax/2.0-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



</head>

<body>
<h1>Trap model analytics</h1>

<p>For ease of analysis, let \( S=S_1=S_2 \) and, \( f_1=f \), and \( J_1 = J_1(1-p) \) Thus,</p>

<p>\[ A = \left[\begin{matrix}0 & f & 0 & 0\\d j q & S & d j & 0\\0 & 0 & 0 & f\\j q \left(- d + 1\right) & 0 & j \left(- d + 1\right) & S\end{matrix}\right] \]</p>

<p>The dominant eigenvalue of \( A \) are 0, \( S \), and</p>

<p>\[ \frac{S}{2} \pm \frac{1}{2} \sqrt{S^2 + 4f (J_1 d +  J_2 (1-d))} \]</p>

<p>The positive root of the more complex eigenvalue will always be the dominant value. For simplicity hereafter square-root term is referred to as \( v \).  Here are sensitivities \( (s) \) of the deterministic growth rate \( (\lambda_d) \):</p>

<p>\[ s_d = \frac{\partial \lambda_d}{\partial d}  = \frac{f(J_1 - J_2)}{v} \]</p>

<p>\[ s_f = \frac{\partial \lambda_d}{\partial f}  = \frac{J_1 d + J_2 (1-d)}{v} \]</p>

<p>\[ s_S = \frac{\partial \lambda_d}{\partial S}  = \frac{1}{2} + \frac{1}{2} \frac{S}{v} \]</p>

<p>\[ s_{J_1} = \frac{\partial \lambda_d}{\partial J_1}  = \frac{df}{v} \]</p>

<p>\[ s_{J_2} = \frac{\partial \lambda_d}{\partial J_2}  = \frac{df}{v} \]</p>

<p>Using Doak&#39;s [-@Doak2005] modification of  Tuljapurkarâ€™s [Tuljapurkar1990] approximation, I calculate an expression for the stochastic growth rate.  :</p>

<p>\[ \log \lambda_s = \log \hat \lambda_d - \frac{1}{2} \left(\frac{\tau}{\hat {\lambda_d}}\right)^2 \]
\[ \tau^2 = \sum_i \sum_j \rho_{i,j} \sigma_i \sigma_j s_i s_j \]</p>

<p>where \( i \) and \( j \) are each of the parameters, \( \sigma \) are their standard deviations, and \( \rho \) their correlations.  For a case where we assume that there is stochasticity in \( J_1 \) and \( J_2 \) but not \( S \)</p>

<p>\[ \begin{aligned}
\tau^2 &= \rho_{J_1, J_2} \sigma_{J_1} \sigma_{J_2} s_{J_1} s_{J_2} + \sigma^2_{J_1} s^2_{J_1} + \sigma^2_{J_1} s^2_{J_2} \\
       &=  \left(\frac{df}{v}\right)^2 \left(\rho_{J_1, J_2} \sigma_{J_1} \sigma_{J_2} + \sigma^2_{J_1} + \sigma^2_{J_1}\right)
\end{aligned} \]</p>

<p>\[ \begin{aligned}
  \log \lambda_s &= \log \lambda_d - \frac{1}{2} \left(\frac{\tau}{ {\lambda_d}}\right)^2 \\
                 &= \log \left(\frac{S + v}{2}\right) - 2 \left(\frac{df}{(S + v)v}\right)^2 \left(\rho_{J_1, J_2} \sigma_{J_1} \sigma_{J_2} + \sigma^2_{J_1} + \sigma^2_{J_2}\right)
\end{aligned} \]</p>

<p>We can simplify even more by assuming that variance is equal in the two patches</p>

<p>\[ \log \lambda_s = \log \left(\frac{S + v}{2}\right) - 2 \left(\frac{df}{(S + v)v}\right)^2 \left((2+\rho)\sigma^2\right) \]</p>

<p>Now calculate the derivative of \( \log \lambda_s \) with respect to \( d \):</p>

<p>\[ \frac{\partial \log \lambda_s}{\partial d} = \frac{2f \left(J_{1} - J_{2}\right)}{(S+v)v} - (2+\rho)\sigma^2 \left(\frac{4df^2}{(S+v)^2 v^2} - \frac{8d^2f^3(J_1-J_2)}{(S+v)^2 v^4} - \frac{8 d^2f^3(J_1-J_2)}{(S+v)^3 v^3}\right) \]</p>

<p>This is ugly but we are interested in where this derivative equals zero.  Setting the left side to zero allows a number of terms to fall out:</p>

<p>\[ 0 = (J_1 - J_2) - (2+\rho)\sigma^2 \left(\frac{2df}{(S+v)v} - \frac{4d^2f^2(J_1-J_2)}{(S+v) v^3} - \frac{4 d^2f^2(J_1-J_2)}{(S+v)^2 v^2}\right) \]</p>

<p>OK, still ugly.  But one solution to this is:</p>

<p>\[ d = \frac{J_2}{J_2 - J_1} = \frac{J_2}{p} \]</p>

<p>(Solved that last one with SymPy but need to check it)</p>

</body>

</html>

